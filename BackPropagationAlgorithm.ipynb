{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "STUDENT_NAME = 'UTTEJ REDDY PAKANATI, SAI ANURAG NEELISETTY, KRISHNA KANTH MUTTA'\n",
    "\n",
    "STUDENT_ID = '20875894, 20911061, 20919166'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fun_sigmoid(z): #sigmoid functon\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def Fun_sigmoid_derivative(z): #derivative of sigmoid function\n",
    "    return np.multiply(z, 1-z)\n",
    "\n",
    "\"\"\"The function \"Initial_weights\" will randomly initialize the weights of the network in the range [-1, 1]. This function takes\n",
    "layers as input and returns weights as a multi-dimensional array. The argument contains first element as input layer, next are \n",
    "hidden layers and the last element as output layer. Here, numpy is being used to generate a random number in the range [-1, 1]\n",
    "for each connection.\"\"\"\n",
    "\n",
    "def Initial_weights(layers_whole):\n",
    "    layers, weights = len(layers_whole), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-1, 1) for k in range(layers_whole[i-1] + 1)]\n",
    "              for j in range(layers_whole[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "    return weights\n",
    "\n",
    "\"\"\"The function \"Accuracy1\" will take input data, actual class and computed weights, pedicts the class of each object in its \n",
    "input and checks it against the actual class and returs the percentage of correct predictions.\"\"\"\n",
    "\n",
    "def Accuracy1(x_data, y_data, weights):\n",
    "    corr = 0\n",
    "    for i in range(len(x_data)):\n",
    "        x, y = x_data[i], list(y_data[i])\n",
    "        guess = Prediction(x, weights)\n",
    "        if(y == guess):\n",
    "            corr += 1\n",
    "    return corr / len(x_data)\n",
    "\n",
    "\"\"\"The fuction \"Forward_propagation\" will take the input data, weights as input. The output is computed by first calculating the\n",
    "dot product between the input and the weights of the layer and then passing this dot product through an activation function. \n",
    "The output of each layer is the input of the next. The output of the final layer is the prediction of the network.\"\"\"\n",
    "\n",
    "def Forward_propagation(x_data, weights, layers):\n",
    "    activations, layer_input = [x_data], x_data\n",
    "    for j in range(layers):\n",
    "        activation = Fun_sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation) # Adding the bias\n",
    "    \n",
    "    return activations\n",
    "\n",
    "\"\"\"The function \"Network\" will take training data, validation data, number of epochs, layers and the learning rate as\n",
    "inputs. Frist, the weights of the network will get randomly initialized by the function Initial_weights. Then, in each epoch,\n",
    "the weights will be updated and after all the epochs, accuracy of the training and validation sets will be printed. We are\n",
    "considering the learning rate as 0.15 for our network\"\"\"\n",
    "\n",
    "def Network(x_data, y_data, x_val=None, y_val=None, epochs=10, layers_whole=[], learn_rate=0.15):\n",
    "    weights = Initial_weights(layers_whole)\n",
    "    acc_train=[]\n",
    "    acc_val=[]\n",
    "    epoch_all=[]\n",
    "    for epoch in range(1, epochs+1):\n",
    "        weights = Training(x_data, y_data, learn_rate, weights)   \n",
    "\n",
    "        if(epoch % 1 == 0):\n",
    "           # print(\"Epoch {}\".format(epoch))\n",
    "           # print(\"Training Accuracy:{}\".format(Accuracy1(x_data, y_data, weights)))\n",
    "            acc_train.append(round(Accuracy1(x_data, y_data, weights),2))\n",
    "            epoch_all.append(epoch)\n",
    "            if x_val.any():\n",
    "             #   print(\"Validation Accuracy:{}\".format(Accuracy1(x_val, y_val, weights)))\n",
    "                acc_val.append(round(Accuracy1(x_val, y_val, weights),2))\n",
    "                \n",
    "  #  from matplotlib import pyplot as plt\n",
    "  #  plt.plot(epoch_all,acc_train);\n",
    "  #  plt.plot(epoch_all,acc_val);\n",
    "  #  plt.show()\n",
    "            \n",
    "    return weights\n",
    "\n",
    "\"\"\"The function \"Back_propagation\" will take actual class, predicted output from forward propogation, computed weights, layers\n",
    "and learning rate as inputs. First error will be calculated and then delta is calcuated as error of current layer times Sigmoid\n",
    "derivation of current layer activation. Weights between the current and pervious layer are updated by using delta and learning\n",
    "rate. In this manner, the function propogates the error backwards to perform the weight updations. \"\"\"\n",
    "\n",
    "def Back_propagation(y_data, activation_op, weights, layers_whole,learn_rate):\n",
    "    out_final = activation_op[-1]\n",
    "    error = np.matrix(y_data - out_final)\n",
    "    \n",
    "    for j in range(layers_whole, 0, -1):\n",
    "        currActivation = activation_op[j]        \n",
    "        if(j > 1):\n",
    "            prevActivation = np.append(1, activation_op[j-1])\n",
    "        else:\n",
    "            prevActivation = activation_op[0]\n",
    "        \n",
    "        delta = np.multiply(error,  Fun_sigmoid_derivative(currActivation))\n",
    "        weights[j-1] += learn_rate * np.multiply(delta.T, prevActivation)\n",
    "        w = np.delete(weights[j-1], [0], axis=1)\n",
    "        error = np.dot(delta, w) \n",
    "    \n",
    "    return weights\n",
    "\n",
    "\"\"\"The function \"Tranining\" will take the input data, actual class, learning rate and initialized weights as input. It\n",
    "first performs the forward propogation,then updates the weights by backward propogation and then final calculated weights\n",
    "are returned\"\"\"\n",
    "\n",
    "def Training(x_data, y_data, learn_rate, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(x_data)):\n",
    "        x, y = x_data[i], y_data[i]\n",
    "        x = np.matrix(np.append(1, x)) # Adding the bias\n",
    "        activations = Forward_propagation(x, weights, layers)\n",
    "        weights = Back_propagation(y, activations, weights, layers,learn_rate)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\"\"\"The function \"Prediction\" will take the input data, computed weights as input. First, forward propogation of the input data \n",
    "is performed using the weights and output of the netwrok is calculated. The output is then converted to one-hot encoding format\n",
    "using the Max_function\"\"\"\n",
    "\n",
    "def Prediction(x_data, weights):\n",
    "    layers_whole = len(weights)\n",
    "    x_data = np.append(1, x_data) # Adding bias\n",
    "    activation_op = Forward_propagation(x_data, weights, layers_whole)    \n",
    "    out_final = activation_op[-1].A1\n",
    "    inx = Max_function(out_final)\n",
    "    # Initialize prediction vector to zeros\n",
    "    y_pred = [0 for i in range(len(out_final))]\n",
    "    y_pred[inx] = 1 \n",
    "    return y_pred\n",
    "\n",
    "\"\"\"The function \"Max_function\" will take the array of values as input and returns the index of the element with highest value\"\"\"\n",
    "\n",
    "def Max_function(out):\n",
    "    x, inx = out[0], 0\n",
    "    for i in range(1, len(out)):\n",
    "        if(out[i] > x):\n",
    "            x, inx = out[i], i\n",
    "    return inx\n",
    "\n",
    "\"\"\"The function \"Accuracy\" will take input data and weights as input, predicts the output for all the input values and returns \n",
    "an array of the calculated outputs.\"\"\"\n",
    "\n",
    "def Accuracy(X, weights):\n",
    "    result=[]\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        guess = Prediction(x, weights)\n",
    "        result.append(guess)\n",
    "    result1=np.array(result)\n",
    "    return result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training data, lables of the training data and splitting it into training and validation datasets\n",
    "\n",
    "df = pd.read_csv('train_data.csv',header=None)\n",
    "arr = df.to_numpy()\n",
    "df_class = pd.read_csv('train_labels.csv',header=None)\n",
    "arr_class = df_class.to_numpy()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(arr, arr_class, test_size = 0.2, random_state = 275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Accuracy:0.9655102762207747\n",
      "Validation Accuracy:0.9606140173702282\n",
      "Epoch 2\n",
      "Training Accuracy:0.9712669797505429\n",
      "Validation Accuracy:0.9664714199151686\n",
      "Epoch 3\n",
      "Training Accuracy:0.9732363783265162\n",
      "Validation Accuracy:0.9680872550999798\n",
      "Epoch 4\n",
      "Training Accuracy:0.9772256728778468\n",
      "Validation Accuracy:0.9701070490809938\n",
      "Epoch 5\n",
      "Training Accuracy:0.9772761702772307\n",
      "Validation Accuracy:0.9703090284790952\n",
      "Epoch 6\n",
      "Training Accuracy:0.9786396000605969\n",
      "Validation Accuracy:0.9719248636639063\n",
      "Epoch 7\n",
      "Training Accuracy:0.9797000454476594\n",
      "Validation Accuracy:0.9721268430620077\n",
      "Epoch 8\n",
      "Training Accuracy:0.9794475584507398\n",
      "Validation Accuracy:0.9719248636639063\n",
      "Epoch 9\n",
      "Training Accuracy:0.9814674544260971\n",
      "Validation Accuracy:0.9717228842658049\n",
      "Epoch 10\n",
      "Training Accuracy:0.9811139726304096\n",
      "Validation Accuracy:0.9721268430620077\n",
      "Epoch 11\n",
      "Training Accuracy:0.9799525324445791\n",
      "Validation Accuracy:0.9717228842658049\n",
      "Epoch 12\n",
      "Training Accuracy:0.9821239206180882\n",
      "Validation Accuracy:0.9735406988487174\n",
      "Epoch 13\n",
      "Training Accuracy:0.9821744180174721\n",
      "Validation Accuracy:0.9727327812563119\n",
      "Epoch 14\n",
      "Training Accuracy:0.9828308842094632\n",
      "Validation Accuracy:0.9731367400525146\n",
      "Epoch 15\n",
      "Training Accuracy:0.9828813816088472\n",
      "Validation Accuracy:0.9731367400525146\n",
      "Epoch 16\n",
      "Training Accuracy:0.9832348634045347\n",
      "Validation Accuracy:0.9723288224601091\n",
      "Epoch 17\n",
      "Training Accuracy:0.9830328738069989\n",
      "Validation Accuracy:0.9721268430620077\n",
      "Epoch 18\n",
      "Training Accuracy:0.983739837398374\n",
      "Validation Accuracy:0.9731367400525146\n",
      "Epoch 19\n",
      "Training Accuracy:0.98368933999899\n",
      "Validation Accuracy:0.9727327812563119\n",
      "Epoch 20\n",
      "Training Accuracy:0.9825278998131596\n",
      "Validation Accuracy:0.9727327812563119\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAisklEQVR4nO3df3Bd5X3n8ffH8q/YBixs4Rjb2AbED4chQDRu0haajJvGpFlcmDY1s7uhFIZ4BrObMjsbIDOdTGaypT+yHXZL8bgJadgSHAL1xpNx+FHPNmxnAVtgQTBIlmwDFnasKwgY2ca25O/+cR85h6srdCxL915Jn9fMnXvO8+Oc5xxf36+ec557HkUEZmZmWZOq3QAzM6s9Dg5mZjaAg4OZmQ3g4GBmZgM4OJiZ2QCTq92AkTB37txYsmRJtZthZjamvPDCC90R0VAub1wEhyVLltDc3FztZpiZjSmS3hgsz5eVzMxsAAcHMzMbwMHBzMwGcHAwM7MBHBzMzGyAXMFB0kpJbZI6JN1VJr9e0kZJL0vaKumyTN6fSdoh6RVJj0iantLPlvS0pPb0Xp+pc3faV5ukL4zEgZqZWX5DBgdJdcD9wLXAMuBGSctKit0DtETE5cBXgPtS3QXAfwKaIuIyoA5YnercBWyJiEZgS1onbXs18AlgJfD3qQ1mZlYheX7nsBzoiIjdAJI2AKuAVzNllgF/ARARrZKWSJqX2cfHJB0HZgD7Uvoq4LNp+QfAvwJfT+kbIuIosEdSR2rDs8M5wPHsxIngH//f67x7+Fi1m2JmVXLRx8/gS5efO+LbzRMcFgB7M+udwG+UlHkJuAH4N0nLgcXAwoh4QdLfAG8CR4CnIuKpVGdeROwHiIj9ks7J7O+5kv0tKG2UpNuA2wDOO++8HIcx/ryy7z2+9dNijJaq3Bgzq4ovXX5u1YJDua+d0hmC7gXuk9QC/ALYDvSm+wirgKXAu8CPJf2HiPin09wfEbEeWA/Q1NQ0IWcsaj/QA8C/3Pk7XHjOrCq3xszGkzzBoRNYlFlfyK8vDQEQEQeBmwEkCdiTXl8A9kREIeX9M/CbwD8BByTNT72G+UBX3v1ZUUehhyl1YvGcGdVuipmNM3lGK20DGiUtlTSV4s3iTdkCkmanPIBbgWdSwHgT+LSkGSlorABeS+U2ATel5ZuAn2TSV0uaJmkp0AhsHd7hjW/tB3pYMmcmU+o8ItnMRtaQPYeI6JW0FniS4mijByNih6Q1KX8dcCnwkKQ+ijeqb0l5z0t6DHgR6KV4uWl92vS9wKOSbqEYRP4o1dkh6dG0nV7g9ojoG6kDHk92FXq4dP4Z1W6GmY1Dihj7l+ubmppioj2V9YPjfSz78ydY+7kLufP3Lq52c8xsDJL0QkQ0lcvz9Ygx6vW3D3Ei4MJ57jmY2chzcBij+kcqXdjgUUpmNvIcHMaojq4eJgnOb5hZ7aaY2Tjk4DBGdXT1sOjsGUyf4ieLmNnIc3AYozq6emj0D9/MbJQ4OIxBvX0n2N3dwwUODmY2ShwcxqA33znM8b6g8RyPVDKz0eHgMAa1d6WRSu45mNkocXAYgzocHMxslDk4jEEdXT3MP2s6s6bleW6imdmpc3AYgzq6etxrMLNR5eAwxpw4EQ4OZjbqHBzGmH3vHeHI8T6PVDKzUeXgMMZ4pJKZVYKDwxizKwUH/zrazEaTg8MY036ghzkzp1I/c+rQhc3MhilXcJC0UlKbpA5Jd5XJr5e0UdLLkrZKuiylXyypJfM6KOlrKe9HmfTXJbWk9CWSjmTy1o3c4Y59HQXfjDaz0TfkQHlJdcD9wOeBTmCbpE0R8Wqm2D1AS0RcL+mSVH5FRLQBV2S28xawESAi/jizj+8A72W2tysirjiN4xqXIoL2A+/z7z55brWbYmbjXJ6ew3KgIyJ2R8QxYAOwqqTMMmALQES0AkskzSsps4Lil/4b2URJAr4MPDKM9k8ohZ6jHPyg1/cbzGzU5QkOC4C9mfXOlJb1EnADgKTlwGJgYUmZ1ZQPAFcDByKiPZO2VNJ2ST+XdHW5Rkm6TVKzpOZCoZDjMMa+jv7Z3zyM1cxGWZ7goDJpUbJ+L1Cf7hvcAWwHek9uQJoKXAf8uMy2buTDQWM/cF5EXAncCfxQ0pkDGhCxPiKaIqKpoaEhx2GMfR2FNFJpnnsOZja68jycpxNYlFlfCOzLFoiIg8DNcPIy0Z706nct8GJEHMjWkzSZYo/jU5ltHQWOpuUXJO0CLgKa8x3S+NV+oIczpk3mnDOmVbspZjbO5ek5bAMaJS1NPYDVwKZsAUmzUx7ArcAzKWD0K+0d9PtdoDUiOjPbakg3r5F0PtAI7M57QONZR1cPF86bRTH+mpmNniF7DhHRK2kt8CRQBzwYETskrUn564BLgYck9QGvArf015c0g+JIp6+W2Xy5+xDXAN+S1Av0AWsi4p1TPrJxqL2rh89dPDEuoZlZdeV65nNEbAY2l6Styyw/S/Ev/HJ1DwNzBsn7kzJpjwOP52nXRPLu4WN09xz1/QYzqwj/QnqM8AQ/ZlZJDg5jRMfJZyp5GKuZjT4HhzGivauH6VMmsWD2x6rdFDObABwcxoiOrh4uaJjFpEkeqWRmo8/BYYzw7G9mVkkODmPAoaO9vPXuET9TycwqxsFhDNhV8EglM6ssB4cx4NfDWD1Sycwqw8FhDGjv6mHyJLF4zoxqN8XMJggHhzGgo6uHpXNnMqXO/1xmVhn+thkDPFLJzCrNwaHGHe3t4423D3mkkplVlINDjdvTfYgTARc4OJhZBTk41Dg/U8nMqsHBoca1H+hBgvMbZla7KWY2gTg41LiOQg/nnT2D6VPqqt0UM5tAcgUHSSsltUnqkHRXmfx6SRslvSxpq6TLUvrFkloyr4OSvpbyvinprUzeFzPbuzvtq03SF0boWMekjgM9XNjg+w1mVllDzgSX5nO+n+JUn53ANkmbIuLVTLF7gJaIuF7SJan8iohoA67IbOctYGOm3t9GxN+U7G8ZxelDPwGcC/yLpIsiom+Yxzhm9fadYE/3IT57iacGNbPKytNzWA50RMTuiDgGbABWlZRZBmwBiIhWYImkeSVlVgC7IuKNIfa3CtgQEUcjYg/Qkdow4bz5zmGO9Z1wz8HMKi5PcFgA7M2sd6a0rJeAGwAkLQcWAwtLyqwGHilJW5suRT0oqf4U9oek2yQ1S2ouFAo5DmPsOTlSaZ5HKplZZeUJDuVml4mS9XuBekktwB3AdqD35AakqcB1wI8zdR4ALqB42Wk/8J1T2B8RsT4imiKiqaFhfF52aU/B4QKPVDKzChvyngPFv9wXZdYXAvuyBSLiIHAzgCQBe9Kr37XAixFxIFPn5LKkfwB+mnd/E8Wurh7mnzWdM6ZPqXZTzGyCydNz2AY0SlqaegCrgU3ZApJmpzyAW4FnUsDodyMll5Qkzc+sXg+8kpY3AaslTZO0FGgEtuY9oPGk3c9UMrMqGbLnEBG9ktYCTwJ1wIMRsUPSmpS/DrgUeEhSH/AqcEt/fUkzKI50+mrJpv9K0hUULxm93p+ftv1o2k4vcPtEHKl04kSwq9DDl5sWDV3YzGyE5bmsRERsBjaXpK3LLD9L8S/8cnUPA3PKpP/Hj9jft4Fv52nbeLXvvSMcPtZH4zz3HMys8vwL6Rp1cvY3D2M1sypwcKhRHsZqZtXk4FCjOrp6OHvmVM6eOXXowmZmI8zBoUZ5pJKZVZODQw2KCE8NamZV5eBQgwo9R3nvyHFPDWpmVePgUINOjlRycDCzKnFwqEGeGtTMqs3BoQZ1dPUwa9pk5p05rdpNMbMJysGhBrUfKN6MLj7D0Mys8hwcalBHwSOVzKy6HBxqzHuHj1N4/6hHKplZVTk41JiOwvuARyqZWXU5ONSY9gMeqWRm1efgUGM6unqYNnkSC+o/Vu2mmNkElis4SFopqU1Sh6S7yuTXS9oo6WVJWyVdltIvltSSeR2U9LWU99eSWlOdjZJmp/Qlko5k6qwr3d941t7VwwUNs6ib5JFKZlY9QwYHSXXA/RTngV4G3ChpWUmxe4CWiLgc+ApwH0BEtEXEFRFxBfAp4DCwMdV5Grgs1dkJ3J3Z3q7+ehGxZthHNwb5mUpmVgvy9ByWAx0RsTsijgEbgFUlZZYBWwAiohVYImleSZkVFL/030jlnoqI3pT3HLBwmMcwbhw+1stb7x7xSCUzq7o8wWEBsDez3pnSsl4CbgCQtBxYzMAv+9XAI4Ps40+Bn2XWl0raLunnkq4uV0HSbZKaJTUXCoUch1H7dnUdAjxSycyqL09wKHfxO0rW7wXqJbUAdwDbgf5eAZKmAtcBPx6wcekbqezDKWk/cF5EXAncCfxQ0pkDGhCxPiKaIqKpoaEhx2HUvv5hrJ432syqbXKOMp3Aosz6QmBftkBEHARuBlDxmQ970qvftcCLEXEgW0/STcCXgBUREWlbR4GjafkFSbuAi4Dm/Ic1NrUf6GHyJLF4zsxqN8XMJrg8PYdtQKOkpakHsBrYlC0gaXbKA7gVeCYFjH43UnJJSdJK4OvAdRFxOJPekG6CI+l8oBHYfWqHNTZ1dPWwZO5MptR5hLGZVdeQPYeI6JW0FngSqAMejIgdktak/HXApcBDkvqAV4Fb+utLmgF8Hvhqyab/DpgGPJ0eMPdcGpl0DfAtSb1AH7AmIt45vcMcGzq6erhonn/8ZmbVl+eyEhGxGdhckrYus/wsxb/wy9U9DMwpk37hIOUfBx7P067x5GhvH2+8c5jfv3x+tZtiZuZfSNeK17sP03ciPFLJzGqCg0ON8NSgZlZLHBxqRHvX+0hwQYODg5lVn4NDjejo6mFR/QymT6mrdlPMzBwcaoWfqWRmtcTBoQb09p1gd/chP1PJzGqGg0MN2PurIxzrPcEFDg5mViMcHGpA/0gl9xzMrFY4ONSA9q7iA/fcczCzWuHgUAM6unr4+JnTOXP6lGo3xcwMcHCoCR6pZGa1xsGhyiLCwcHMao6DQ5Xte+8DDh/rc3Aws5ri4FBlHqlkZrXIwaHK2g8URyq552BmtcTBocp2FXo4e+ZU5syaVu2mmJmdlCs4SFopqU1Sh6S7yuTXS9oo6WVJWyVdltIvltSSeR2U9LWUd7akpyW1p/f6zPbuTvtqk/SFETrWmtR+oIcL/SRWM6sxQwaHNJ/z/cC1wDLgRknLSordA7RExOXAV4D7ACKiLSKuiIgrgE8Bh4GNqc5dwJaIaAS2pHXStlcDnwBWAn/fP6f0eBMRtHf1cOE8Bwczqy15pgldDnRExG4ASRuAVRTniu63DPgLgIholbRE0ryIOJApswLYFRFvpPVVwGfT8g+AfwW+ntI3RMRRYI+kjtSGZ0/98D7a692H+MsnWoddf8qJD/jj7r/jY309w6ofBH/Re5RL958JP5ox7HaY2QR23qfhM7eP+GbzBIcFwN7MeifwGyVlXgJuAP5N0nJgMbAQyAaH1cAjmfV5EbEfICL2Szons7/nSva3oLRRkm4DbgM477zzchzGQEd7T7CrMLwvdoCrjm/ntw5vZt+kj3OMqcPaxtyp4uO970G3b/+Y2TDMHt7331DyBAeVSYuS9XuB+yS1AL8AtgO9JzcgTQWuA+4eof0REeuB9QBNTU0D8vO4+ONn8NSf/c5wqhY99yo8Aefe+X9h1jlDlzczGyPyBIdOYFFmfSGwL1sgIg4CNwNIErAnvfpdC7xYcpnpgKT5qdcwH+jKu7+aUWiDj9XDzIZqt8TMbETluZaxDWiUtDT1AFYDm7IFJM1OeQC3As+kgNHvRj58SYm0jZvS8k3ATzLpqyVNk7QUaAS25j2giiq0wdyLQeU6O2ZmY9eQPYeI6JW0FngSqAMejIgdktak/HXApcBDkvoo3qi+pb++pBnA54Gvlmz6XuBRSbcAbwJ/lLa3Q9KjaTu9wO0R0Xd6hzlKutvgki9VuxVmZiMuz2UlImIzsLkkbV1m+VmKf+GXq3sYmFMm/W2KI5jK1fk28O08bauaQ91w+G1ouLjaLTEzG3EeIjNchbbiu4ODmY1DDg7DVUi/j5jr4GBm44+Dw3B174Sps+CshdVuiZnZiHNwGK5CK8xt9EglMxuXHByGq7DTl5TMbNxycBiODw7C+/t8M9rMxi0Hh+Ho3ll8d3Aws3HKwWE4Tg5jvaS67TAzGyUODsNRaIW6qTB7cbVbYmY2KhwchqN7J8xphLpcPzA3MxtzHByGo9AKDRdVuxVmZqPGweFUHT8Cv3rD9xvMbFxzcDhV3e1AwFz3HMxs/HJwOFUnh7G652Bm45eDw6kqtIImwZwLqt0SM7NR4+BwqgptcPb5MHlatVtiZjZqcgUHSSsltUnqkHRXmfx6SRslvSxpq6TLMnmzJT0mqVXSa5I+k9J/JKklvV6X1JLSl0g6kslbV7q/quqfGtTMbBwbcqC+pDrgfopTfXYC2yRtiohXM8XuAVoi4npJl6Ty/bO83Qc8ERF/mOaZngEQEX+c2cd3gPcy29sVEVcM/7BGSd9xeGcXXPL71W6JmdmoytNzWA50RMTuiDgGbABWlZRZBmwBiIhWYImkeZLOBK4BvpfyjkXEu9mKkgR8GXjkdA6kIt7ZDSd6/UwlMxv38gSHBcDezHpnSst6CbgBQNJyYDGwEDgfKADfl7Rd0nclzSypezVwICLaM2lLU/mfS7q6XKMk3SapWVJzoVDIcRgjwFODmtkEkSc4lJvNJkrW7wXq032DO4DtQC/Fy1ZXAQ9ExJXAIaD0nsWNfLjXsB84L5W/E/hh6oF8uAER6yOiKSKaGhoachzGCOgPDv6Ng5mNc3keDtQJLMqsLwT2ZQtExEHgZjh5mWhPes0AOiPi+VT0MTLBQdJkij2OT2W2dRQ4mpZfkLQLuAhoPpUDGxXdbXDWeTC1tPNjZja+5Ok5bAMaJS1NN5RXA5uyBdKIpKlp9VbgmYg4GBG/BPZK6r8OswLI3sj+XaA1Ijoz22pIN8GRdD7QCOwexrGNPD9TycwmiCF7DhHRK2kt8CRQBzwYETskrUn564BLgYck9VH88r8ls4k7gIdT8NhN6mEkqxl4I/oa4FuSeoE+YE1EvDOsoxtJJ/qKj85Y+jvVbomZ2ajL9czpiNgMbC5JW5dZfpbiX/jl6rYATYPk/UmZtMeBx/O0q6LefRN6P/D9BjObEPwL6bz8TCUzm0AcHPIqtBbffc/BzCYAB4e8Cjth1jz4WH21W2JmNuocHPIqtPp+g5lNGA4OeUQU7zn4foOZTRAODnm8vx+OHvRjM8xswnBwyMPPVDKzCcbBIY+Tz1RycDCzicHBIY/uNpg+G2adU+2WmJlVhINDHoW24iUllXtArZnZ+OPgkEd/cDAzmyAcHIZy6G043O37DWY2oTg4DKW7f6SSf+NgZhOHg8NQ/EwlM5uAHByGUtgJU2bAmQur3RIzs4rJFRwkrZTUJqlDUukc0Eiql7RR0suStkq6LJM3W9JjklolvSbpMyn9m5LektSSXl/M1Lk77atN0hdG4kCHrf+ZSpMcR81s4hhysp80Zef9wOcpzie9TdKmiMhO93kP0BIR10u6JJVfkfLuA56IiD9Ms8HNyNT724j4m5L9LaM4Q9wngHOBf5F0UUT0De8QT1P3Tljy21XZtZlZteT5c3g50BERuyPiGLABWFVSZhmwBSAiWoElkuZJOpPitJ/fS3nHIuLdIfa3CtgQEUcjYg/QkdpQeR8chINveRirmU04eYLDAmBvZr0zpWW9BNwAIGk5sBhYCJwPFIDvS9ou6buSZmbqrU2Xoh6U1D9RQp79Iek2Sc2SmguFQo7DGIbu9uK7h7Ga2QSTJziU+1lwlKzfC9RLagHuALYDvRQvW10FPBARVwKHgP57Fg8AFwBXAPuB75zC/oiI9RHRFBFNDQ0NOQ5jGDyM1cwmqCHvOVD8y31RZn0hsC9bICIOAjcDSBKwJ71mAJ0R8Xwq+hgpOETEgf76kv4B+Gne/VVMoRXqpkL9kqrs3sysWvL0HLYBjZKWphvKq4FN2QJpRNLUtHor8ExEHIyIXwJ7JfVfl1kBvJrqzM9s4nrglbS8CVgtaZqkpUAjsHUYx3b6CjthzoVQlyeGmpmNH0N+60VEr6S1wJNAHfBgROyQtCblrwMuBR6S1Efxy/+WzCbuAB5OwWM3qYcB/JWkKyheMnod+Gra3g5Jj6bt9AK3V22kUqEV5n+yKrs2M6smRQy4nD/mNDU1RXNz88hu9PgR+G/nwjX/FT5398hu28ysBkh6ISKayuX5l12DebsD4oQfm2FmE5KDw2AKHqlkZhOXg8NgCm2gScUb0mZmE4yDw2C626B+KUyeVu2WmJlVnIPDYDz7m5lNYA4O5fQdh7d3OTiY2YTl4FDOO3vgxHE/U8nMJiwHh3JOPlPJwcHMJiYHh3L6pwad6984mNnE5OBQTmEnnLUIps2qdkvMzKrCwaGc/qlBzcwmKAeHUidOFCf58S+jzWwCc3Ao9d6b0HvEz1QyswnNwaFUYWfx3T0HM5vAHBxKeaSSmZmDwwDdbTDzHJhxdrVbYmZWNbmCg6SVktokdUi6q0x+vaSNkl6WtFXSZZm82ZIek9Qq6TVJn0npf53SXk51Z6f0JZKOSGpJr3UjdKz5+JlKZmZDBwdJdcD9wLXAMuBGSctKit0DtETE5cBXgPsyefcBT0TEJcAngddS+tPAZanOTiA73dquiLgivdYM47iGJ6J4z8HBwcwmuDw9h+VAR0TsjohjwAZgVUmZZcAWgIhoBZZImifpTOAa4Hsp71hEvJuWn4qI3lT/OWDh6R7MaXv/l3D0PT9TycwmvDzBYQGwN7PemdKyXgJuAJC0HFhM8cv+fKAAfF/SdknflTSzzD7+FPhZZn1pKv9zSVeXa5Sk2yQ1S2ouFAo5DiMHP1PJzAzIFxxUJi1K1u8F6iW1AHcA24FeYDJwFfBARFwJHAI+dM9C0jdS2YdT0n7gvFT+TuCHqQfy4QZErI+IpohoamhoyHEYORQcHMzMoPjlPZROYFFmfSGwL1sgIg4CNwNIErAnvWYAnRHxfCr6GJngIOkm4EvAioiItK2jwNG0/IKkXcBFQPOpHtwpK7TB9LNg1rxR35WZWS3L03PYBjRKWippKrAa2JQtkEYkTU2rtwLPRMTBiPglsFdS/5/iK4BXU52VwNeB6yLicGZbDekmOJLOBxqB3cM+wlNRaCveb1C5zpKZ2cQxZM8hInolrQWeBOqAByNih6Q1KX8dcCnwkKQ+il/+t2Q2cQfwcAoeu0k9DODvgGnA08XOBs+lkUnXAN+S1Av0AWsi4p3TP9QcutvgopUV2ZWZWS3Lc1mJiNgMbC5JW5dZfpbiX/jl6rYATWXSLxyk/OPA43naNaIOvwOHCr7fYGaGfyH9aydvRvuZSmZmDg79/EwlM7OTHBz6de+EKTOKM8CZmU1wDg79Cq0wtxEm+ZSYmfmbsF9hpx+bYWaWODgAHH0fDnZ6pJKZWeLgAMX7DeDgYGaWODiApwY1Myvh4ADFm9GTpkD90mq3xMysJjg4QPGy0pwLoS7XD8bNzMY9Bwco9hwa/OM3M7N+Dg7HP4Bfve77DWZmGQ4Ob3dAnPBjM8zMMhwcuv3APTOzUg4OhTbQpOINaTMzAxwcisGhfglMmV7tlpiZ1YxcwUHSSkltkjok3VUmv17SRkkvS9oq6bJM3mxJj0lqlfSapM+k9LMlPS2pPb3XZ+rcnfbVJukLI3Ggg+qfGtTMzE4aMjik+ZzvB64FlgE3SlpWUuweoCUiLge+AtyXybsPeCIiLgE+CbyW0u8CtkREI7AlrZO2vRr4BLAS+Pv+OaVHXF9v8Ya0H5thZvYheXoOy4GOiNgdEceADcCqkjLLKH7BExGtwBJJ8ySdSXFO6O+lvGMR8W6qswr4QVr+AfAHmfQNEXE0IvYAHakNI+9Xe+DEcQcHM7MSeYLDAmBvZr0zpWW9BNwAIGk5sBhYCJwPFIDvS9ou6buSZqY68yJiP0B6P+cU9oek2yQ1S2ouFAo5DqOMCFi2CuZ/cnj1zczGqTzBQWXSomT9XqBeUgtwB7Ad6AUmA1cBD0TElcAh0uWj09wfEbE+IpoioqmhoWGITQ6i4SL48kMw7xPDq29mNk7leZhQJ5CdO3MhsC9bICIOAjcDSBKwJ71mAJ0R8Xwq+hi/Dg4HJM2PiP2S5gNdefdnZmajK0/PYRvQKGmppKkUbxZvyhZII5KmptVbgWci4mBE/BLYK6n/ov4K4NW0vAm4KS3fBPwkk75a0jRJS4FGYOswjs3MzIZpyJ5DRPRKWgs8CdQBD0bEDklrUv464FLgIUl9FL/8b8ls4g7g4RQ8dpN6GBQvRT0q6RbgTeCP0vZ2SHo0bacXuD0i+k7/UM3MLC9FDLicP+Y0NTVFc3NztZthZjamSHohIprK5fkX0mZmNoCDg5mZDeDgYGZmAzg4mJnZAOPihrSkAvBGtdvxEeYC3dVuxEdw+06P23d63L7TczrtWxwRZX9FPC6CQ62T1DzYiIBa4PadHrfv9Lh9p2e02ufLSmZmNoCDg5mZDeDgUBnrq92AIbh9p8ftOz1u3+kZlfb5noOZmQ3gnoOZmQ3g4GBmZgM4OIwASYsk/R9Jr0naIek/lynzWUnvSWpJrz+vcBtfl/SLtO8BTylU0f+Q1CHpZUlXVbBtF2fOS4ukg5K+VlKm4udP0oOSuiS9kkk7W9LTktrTe/0gdVdKakvnc6gJrkayfX8tqTX9G26UNHuQuh/5eRjF9n1T0luZf8cvDlK3WufvR5m2vZ4mMCtXd1TP32DfKRX9/EWEX6f5AuYDV6XlM4CdwLKSMp8FflrFNr4OzP2I/C8CP6M4E9+ngeer1M464JcUf5xT1fNHcf7zq4BXMml/BdyVlu8C/nKQY9hFcZrcqRSn0V1Wofb9HjA5Lf9lufbl+TyMYvu+CfyXHJ+Bqpy/kvzvAH9ejfM32HdKJT9/7jmMgIjYHxEvpuX3gdcoM+91jVsFPBRFzwGz0wx9lbYC2BURVf/Fe0Q8A7xTkrwK+EFa/gHwB2WqLgc6ImJ3RBwDNqR6o96+iHgqInrT6nMUZ1KsikHOXx5VO3/90oyWXwYeGen95vER3ykV+/w5OIwwSUuAK4Hny2R/RtJLkn4mqdITVwfwlKQXJN1WJn8BsDez3kl1AtxqBv8PWc3z129eROyH4n9g4JwyZWrlXP4pxd5gOUN9HkbT2nTZ68FBLovUwvm7GjgQEe2D5Ffs/JV8p1Ts8+fgMIIkzQIeB74WxXm1s16keKnkk8D/BP53hZv3WxFxFXAtcLuka0ryVaZORcc5qzhb4HXAj8tkV/v8nYpaOJffoDiT4sODFBnq8zBaHgAuAK4A9lO8dFOq6ucPuJGP7jVU5PwN8Z0yaLUyaad8/hwcRoikKRT/ER+OiH8uzY/inNo9aXkzMEXS3Eq1LyL2pfcuYCPFrmdWJ7Aos74Q2FeZ1p10LfBiRBwozaj2+cs40H+5Lb13lSlT1XMp6SbgS8C/j3QRulSOz8OoiIgDEdEXESeAfxhkv9U+f5OBG4AfDVamEudvkO+Uin3+HBxGQLo++T3gtYj474OU+Xgqh6TlFM/92xVq30xJZ/QvU7xp+UpJsU3AV1T0aeC9/u5rBQ3611o1z1+JTcBNafkm4CdlymwDGiUtTb2h1aneqJO0Evg6cF1EHB6kTJ7Pw2i1L3sf6/pB9lu185f8LtAaEZ3lMitx/j7iO6Vyn7/Ruts+kV7Ab1Pstr0MtKTXF4E1wJpUZi2wg+LIgeeA36xg+85P+30pteEbKT3bPgH3Uxzl8AugqcLncAbFL/uzMmlVPX8UA9V+4DjFv8ZuAeYAW4D29H52KnsusDlT94sUR5js6j/fFWpfB8Xrzf2fw3Wl7Rvs81Ch9v2v9Pl6meIX1vxaOn8p/R/7P3eZshU9fx/xnVKxz58fn2FmZgP4spKZmQ3g4GBmZgM4OJiZ2QAODmZmNoCDg5mZDeDgYGZmAzg4mJnZAP8fxx7F1wnj324AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculating and plotting the traning and validation accuracies to check overfitting of the data\n",
    "\n",
    "layers = [len(x_train[0]) ,5, len(y_train[0])] # Number of nodes in layers\n",
    "weights = Network(x_train, y_train,x_valid, y_valid, epochs=20,layers_whole=layers, learn_rate=0.15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the above plot on the validation and training accuracy, we see that the accuracy stops increasing on validation set from epoch 4 but keeps increasing on training set resulting in overfitting. Hence, we must stop the traning at epoch 4 to avoid the problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuting the weights of the network with number of epochs for training the data as 4.\n",
    "\n",
    "layers = [len(x_train[0]) ,5, len(y_train[0])] # Number of nodes in layers\n",
    "weights = Network(x_train, y_train,x_valid, y_valid, epochs=4,layers_whole=layers, learn_rate=0.15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[ 1.03869105, -0.56764909, -0.46472652, ..., -0.09655005,\n",
       "          -0.39338642,  0.69626284],\n",
       "         [ 0.49678538,  0.68567222,  0.50373969, ...,  0.44512408,\n",
       "          -0.6314685 , -0.0116429 ],\n",
       "         [ 0.65868166,  0.21691882,  0.80007177, ..., -0.49972123,\n",
       "           0.98002777,  0.38861324],\n",
       "         [ 0.57548069, -0.68572412,  0.99386244, ...,  0.30837376,\n",
       "           0.84731969, -0.33223822],\n",
       "         [ 0.14317477, -0.75835142, -0.57020418, ...,  0.53233953,\n",
       "          -0.92908648, -0.4220319 ]]),\n",
       " matrix([[ 0.14112499, -5.63732223,  2.89433914, -3.93787854,  0.75799228,\n",
       "          -2.37439344],\n",
       "         [-1.3761052 , -1.85391977, -3.77237515,  3.06458006, -0.89199365,\n",
       "           5.37390764],\n",
       "         [-5.92830349,  4.15491505,  4.4962526 ,  3.60184518, -2.15989215,\n",
       "          -4.35631108],\n",
       "         [-0.43171585,  4.02474298, -4.63983482, -3.90535804,  0.08465009,\n",
       "          -4.11643865]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('A1_G55.pkl','wb') as pickle_file:\n",
    "    pickle.dump(weights, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is our implementation of backpropagation algorithm. First, we initialize the weights for the network. Next, forward propogation is performed using the initialized weights and then the weights are updated using backpropagation. Prediction is done using the finalized weights.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "Activation Function - Sigmoid     \n",
    "Learning Rate - 0.15     \n",
    "Output function for one-hot encoding - Max_function (user defined)    \n",
    "No of hidden layers - 1 (As suggested)    \n",
    "No of nodes in hidden layer - 5    \n",
    "No of epochs for training - 20, 4(final)    \n",
    "\n",
    "\n",
    "Once the training is done, the resultant weights are stored in A1_G55.pkl file. \n",
    "\n",
    "test_mlp.py file contains the function which will load the weights from .pkl file and gives the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
